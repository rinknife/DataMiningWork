{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8de255e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd  # 用于数据处理和分析\n",
    "import numpy as np  # 用于数值计算\n",
    "import matplotlib.pyplot as plt  # 用于数据可视化\n",
    "import seaborn as sns  # 用于高级数据可视化\n",
    "import os  # 用于操作系统相关功能，如文件路径操作\n",
    "import datetime  # 用于处理日期和时间\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler  # 用于数据预处理（标准化、编码等）\n",
    "from sklearn.impute import SimpleImputer  # 用于处理缺失值\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score  # 用于数据集划分和交叉验证\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  # 用于评估模型性能（AUC指标）\n",
    "import xgboost as xgb  # XGBoost模型库\n",
    "import lightgbm as lgb  # LightGBM模型库\n",
    "from catboost import CatBoostClassifier  # CatBoost模型库\n",
    "from sklearn.linear_model import LogisticRegression  # 用于逻辑回归模型\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier  # 用于集成学习模型\n",
    "import warnings  # 用于忽略警告信息\n",
    "warnings.filterwarnings('ignore')  # 忽略所有警告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2901105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，保证结果可复现\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d85e7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):#把数据类型转换为更小的类型\n",
    "    \"\"\"\n",
    "    减少内存使用的函数\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('初始内存占用: {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('优化后内存占用: {:.2f} MB'.format(end_mem))\n",
    "    print('内存减少了 {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "123b4b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据...\n",
      "初始内存占用: 286.87 MB\n",
      "优化后内存占用: 69.46 MB\n",
      "内存减少了 75.8%\n",
      "初始内存占用: 70.19 MB\n",
      "优化后内存占用: 17.19 MB\n",
      "内存减少了 75.5%\n",
      "训练集大小: (800000, 47)\n",
      "测试集大小: (200000, 46)\n"
     ]
    }
   ],
   "source": [
    "# ===================== 数据集简易处理 ===================== #\n",
    "# 数据读取\n",
    "print('读取数据...')\n",
    "train_data = pd.read_csv(r\"train.csv\")\n",
    "test_data = pd.read_csv(r\"testA.csv\")\n",
    "# 读取提交文件\n",
    "if os.path.exists('submission.csv'):\n",
    "    submission = pd.read_csv('submission.csv')\n",
    "else:\n",
    "    submission = pd.DataFrame({'id': test_data['id'], 'isDefault': 0})\n",
    "\n",
    "# 减少训练集、测试集内存占用\n",
    "train_data = reduce_mem_usage(train_data)\n",
    "test_data = reduce_mem_usage(test_data)\n",
    "\n",
    "# 显示数据集大小\n",
    "print(f'训练集大小: {train_data.shape}')\n",
    "print(f'测试集大小: {test_data.shape}')\n",
    "\n",
    "# 合并数据集，方便同时进行数据处理\n",
    "target = 'isDefault'  # 目标变量名 是否违约\n",
    "train_target = train_data[target]\n",
    "#保存id\n",
    "train_id = train_data['id']\n",
    "test_id = test_data['id']\n",
    "\n",
    "# 删除ID列，因为id列仅用于标识，不参与建模，所以需要删除\n",
    "train_data = train_data.drop(['id', target], axis=1)\n",
    "test_data = test_data.drop(['id'], axis=1)\n",
    "\n",
    "# 合并数据，便于后续处理\n",
    "data_all = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c1e0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行数据探索...\n",
      "数据基本信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 45 columns):\n",
      " #   Column              Non-Null Count    Dtype   \n",
      "---  ------              --------------    -----   \n",
      " 0   loanAmnt            1000000 non-null  float16 \n",
      " 1   term                1000000 non-null  int8    \n",
      " 2   interestRate        1000000 non-null  float16 \n",
      " 3   installment         1000000 non-null  float16 \n",
      " 4   grade               1000000 non-null  category\n",
      " 5   subGrade            1000000 non-null  category\n",
      " 6   employmentTitle     999999 non-null   float32 \n",
      " 7   employmentLength    941459 non-null   category\n",
      " 8   homeOwnership       1000000 non-null  int8    \n",
      " 9   annualIncome        1000000 non-null  float32 \n",
      " 10  verificationStatus  1000000 non-null  int8    \n",
      " 11  issueDate           1000000 non-null  object  \n",
      " 12  purpose             1000000 non-null  int8    \n",
      " 13  postCode            999999 non-null   float16 \n",
      " 14  regionCode          1000000 non-null  int8    \n",
      " 15  dti                 999700 non-null   float16 \n",
      " 16  delinquency_2years  1000000 non-null  float16 \n",
      " 17  ficoRangeLow        1000000 non-null  float16 \n",
      " 18  ficoRangeHigh       1000000 non-null  float16 \n",
      " 19  openAcc             1000000 non-null  float16 \n",
      " 20  pubRec              1000000 non-null  float16 \n",
      " 21  pubRecBankruptcies  999479 non-null   float16 \n",
      " 22  revolBal            1000000 non-null  float32 \n",
      " 23  revolUtil           999342 non-null   float16 \n",
      " 24  totalAcc            1000000 non-null  float16 \n",
      " 25  initialListStatus   1000000 non-null  int8    \n",
      " 26  applicationType     1000000 non-null  int8    \n",
      " 27  earliesCreditLine   1000000 non-null  object  \n",
      " 28  title               999999 non-null   float16 \n",
      " 29  policyCode          1000000 non-null  float16 \n",
      " 30  n0                  949619 non-null   float16 \n",
      " 31  n1                  949619 non-null   float16 \n",
      " 32  n2                  949619 non-null   float16 \n",
      " 33  n3                  949619 non-null   float16 \n",
      " 34  n4                  958367 non-null   float16 \n",
      " 35  n5                  949619 non-null   float16 \n",
      " 36  n6                  949619 non-null   float16 \n",
      " 37  n7                  949619 non-null   float16 \n",
      " 38  n8                  949618 non-null   float16 \n",
      " 39  n9                  949619 non-null   float16 \n",
      " 40  n10                 958367 non-null   float16 \n",
      " 41  n11                 912673 non-null   float16 \n",
      " 42  n12                 949619 non-null   float16 \n",
      " 43  n13                 949619 non-null   float16 \n",
      " 44  n14                 949619 non-null   float16 \n",
      "dtypes: category(3), float16(30), float32(3), int8(7), object(2)\n",
      "memory usage: 93.5+ MB\n",
      "None\n",
      "数值型特征数量: 40\n",
      "类别型特征数量: 5\n",
      "包含缺失值的列: ['employmentTitle', 'employmentLength', 'postCode', 'dti', 'pubRecBankruptcies', 'revolUtil', 'title', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n",
      "包含缺失值的列数量: 22\n"
     ]
    }
   ],
   "source": [
    "# ===================== 数据探索 ===================== #\n",
    "print('进行数据探索...')\n",
    "\n",
    "# 显示基本信息\n",
    "print('数据基本信息:')\n",
    "print(data_all.info())\n",
    "\n",
    "# 数值型变量分析\n",
    "numerical_fea = list(data_all.select_dtypes(include=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns)\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea, list(data_all.columns)))\n",
    "print(f'数值型特征数量: {len(numerical_fea)}')\n",
    "\n",
    "# 类别型变量分析 上面那个是排除法，这个是包含法\n",
    "# 这里将object和category类型的特征都视为类别型特征\n",
    "category_fea = list(data_all.select_dtypes(include=['object', 'category']).columns)\n",
    "print(f'类别型特征数量: {len(category_fea)}')\n",
    "\n",
    "# 查看缺失值情况\n",
    "missing_data = data_all.isnull().sum()\n",
    "missing_cols = missing_data[missing_data > 0].index.tolist()\n",
    "print(f'包含缺失值的列: {missing_cols}')\n",
    "print(f'包含缺失值的列数量: {len(missing_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "080fa489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行特征工程...\n"
     ]
    }
   ],
   "source": [
    "# ===================== 特征工程 ===================== #\n",
    "print('进行特征工程...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36d247",
   "metadata": {},
   "source": [
    "# 这个地方将连续变量离散化为5个离散变量，也许可以修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbc37896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 时间特征处理 --------\n",
    "# 将issueDate转换为时间格式并提取更多时间特征\n",
    "for data in [data_all]:\n",
    "    # 转换时间格式，将字符串转换为日期时间对象\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'], format='%Y-%m-%d')\n",
    "    \n",
    "    # 提取基本时间特征，包括年、月、日、星期几、季度等\n",
    "    data['issueDateYear'] = data['issueDate'].dt.year\n",
    "    data['issueDateMonth'] = data['issueDate'].dt.month\n",
    "    data['issueDateDay'] = data['issueDate'].dt.day\n",
    "    data['issueDateWeekday'] = data['issueDate'].dt.weekday\n",
    "    data['issueDateQuarter'] = data['issueDate'].dt.quarter\n",
    "    \n",
    "    # 计算相对日期（距离2007-06-01的天数）\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x-startdate).dt.days\n",
    "\n",
    "# 处理earliesCreditLine特征，最早开通账户时间\n",
    "data_all['earliesCreditLine'] = pd.to_datetime(data_all['earliesCreditLine'], format='%b-%Y', errors='coerce')\n",
    "\n",
    "# 创建信用历史年龄特征，单位是月份\n",
    "data_all['creditAge'] = (data_all['issueDate'].dt.year - data_all['earliesCreditLine'].dt.year) * 12 + \\\n",
    "                       (data_all['issueDate'].dt.month - data_all['earliesCreditLine'].dt.month)\n",
    "\n",
    "# 提取earliesCreditLine的月份和年份作为特征\n",
    "data_all['earliesCreditLineYear'] = data_all['earliesCreditLine'].dt.year\n",
    "data_all['earliesCreditLineMonth'] = data_all['earliesCreditLine'].dt.month\n",
    "\n",
    "# 计算信用年龄分类，分为五类，连续变量离散化\n",
    "data_all['creditAgeBin'] = pd.qcut(data_all['creditAge'].clip(lower=0), 5, labels=False, duplicates='drop')\n",
    "\n",
    "# 删除原始日期列，只保留处理后的特征\n",
    "data_all.drop(['issueDate', 'earliesCreditLine'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f40b2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 缺失值处理 --------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9223da5",
   "metadata": {},
   "source": [
    "# 缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268371a5",
   "metadata": {},
   "source": [
    "# ====== 处理employmentLength特征 ======\n",
    "# 步骤1：统一转换为字符串类型并处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0230a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['employmentLength'] = data_all['employmentLength'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b696fa",
   "metadata": {},
   "source": [
    "# 步骤2：标准化字符串格式（处理所有可能的格式变化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32e9b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['employmentLength'] = (\n",
    "    data_all['employmentLength']\n",
    "    .str.strip()       # 第一步：去除首尾空格\n",
    "    .str.lower()       # 第二步：统一小写\n",
    "    .replace({         # 第三步：替换不规则字符串\n",
    "        '< 1 year': '0',         # 小于1年 → 0\n",
    "        '10+ years': '10',       # 10年以上 → 10\n",
    "        'nan': np.nan,           # 字符串 'nan' 转成实际的缺失值\n",
    "        'n/a': np.nan,           # 表示空的、不可用的也设为缺失\n",
    "        '': np.nan               # 空字符串也设为缺失\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "279ca0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤3：安全提取数值\n",
    "def safe_extract(value):\n",
    "    try:\n",
    "        # 首先检查value是否为nan\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "            \n",
    "        # 如果已经是数字类型，直接返回\n",
    "        if isinstance(value, (int, float)):\n",
    "            return value\n",
    "            \n",
    "        # 处理浮点型字符串（如\"5.0\"）\n",
    "        if isinstance(value, str) and '.' in value:\n",
    "            return float(value.split()[0])\n",
    "            \n",
    "        # 处理整数型字符串（如\"5 years\"）\n",
    "        if isinstance(value, str):\n",
    "            return int(value.split()[0])\n",
    "            \n",
    "        return np.nan\n",
    "    except (ValueError, AttributeError, IndexError, TypeError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2963f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_all['employmentLength'] = data_all['employmentLength'].apply(safe_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414060be",
   "metadata": {},
   "source": [
    "# 这里填充缺失值的方法是不是可以考虑修改一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5097f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤4：中位数填充缺失值\n",
    "median_value = data_all['employmentLength'].median()\n",
    "data_all['employmentLength'] = data_all['employmentLength'].fillna(median_value).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "595b6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employmentLength处理后取值分布:\n",
      "employmentLength\n",
      "10    328525\n",
      "6     105123\n",
      "2      90565\n",
      "0      80226\n",
      "3      80163\n",
      "1      65671\n",
      "5      62645\n",
      "4      59818\n",
      "8      45168\n",
      "7      44230\n",
      "9      37866\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 步骤5：验证处理结果\n",
    "print(\"employmentLength处理后取值分布:\")\n",
    "print(data_all['employmentLength'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78565e26",
   "metadata": {},
   "source": [
    "# 这里异常值处理和缺失值填充的方法是否可以修改呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7fef66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列 loanAmnt 的异常值比例: 0.0000\n",
      "列 loanAmnt 使用3sigma法则处理异常值\n",
      "列 term 的异常值比例: 0.0000\n",
      "列 term 使用3sigma法则处理异常值\n",
      "列 interestRate 的异常值比例: 0.0000\n",
      "列 interestRate 使用3sigma法则处理异常值\n",
      "列 installment 的异常值比例: 0.0000\n",
      "列 installment 使用3sigma法则处理异常值\n",
      "列 employmentTitle 的异常值比例: 0.0000\n",
      "列 employmentTitle 使用3sigma法则处理异常值\n",
      "列 homeOwnership 的异常值比例: 0.0004\n",
      "列 homeOwnership 使用3sigma法则处理异常值\n",
      "列 annualIncome 的异常值比例: 0.0073\n",
      "列 annualIncome 使用3sigma法则处理异常值\n",
      "列 verificationStatus 的异常值比例: 0.0000\n",
      "列 verificationStatus 使用3sigma法则处理异常值\n",
      "列 purpose 的异常值比例: 0.0213\n",
      "列 purpose 使用四分位法处理异常值\n",
      "列 postCode 的异常值比例: 0.0000\n",
      "列 postCode 使用3sigma法则处理异常值\n",
      "列 regionCode 的异常值比例: 0.0000\n",
      "列 regionCode 使用3sigma法则处理异常值\n",
      "列 dti 的异常值比例: 0.0000\n",
      "列 dti 使用3sigma法则处理异常值\n",
      "列 delinquency_2years 的异常值比例: 0.0000\n",
      "列 delinquency_2years 使用3sigma法则处理异常值\n",
      "列 ficoRangeLow 的异常值比例: 0.0000\n",
      "列 ficoRangeLow 使用3sigma法则处理异常值\n",
      "列 ficoRangeHigh 的异常值比例: 0.0000\n",
      "列 ficoRangeHigh 使用3sigma法则处理异常值\n",
      "列 openAcc 的异常值比例: 0.0000\n",
      "列 openAcc 使用3sigma法则处理异常值\n",
      "列 pubRec 的异常值比例: 0.0000\n",
      "列 pubRec 使用3sigma法则处理异常值\n",
      "列 pubRecBankruptcies 的异常值比例: 0.0000\n",
      "列 pubRecBankruptcies 使用3sigma法则处理异常值\n",
      "列 revolBal 的异常值比例: 0.0125\n",
      "列 revolBal 使用四分位法处理异常值\n",
      "列 revolUtil 的异常值比例: 0.0000\n",
      "列 revolUtil 使用3sigma法则处理异常值\n",
      "列 totalAcc 的异常值比例: 0.0000\n",
      "列 totalAcc 使用3sigma法则处理异常值\n",
      "列 initialListStatus 的异常值比例: 0.0000\n",
      "列 initialListStatus 使用3sigma法则处理异常值\n",
      "列 applicationType 的异常值比例: 0.0193\n",
      "列 applicationType 使用四分位法处理异常值\n",
      "列 title 的异常值比例: 0.0000\n",
      "列 title 使用3sigma法则处理异常值\n",
      "列 policyCode 的异常值比例: 0.0000\n",
      "列 policyCode 使用3sigma法则处理异常值\n",
      "列 n0 的异常值比例: 0.0000\n",
      "列 n0 使用3sigma法则处理异常值\n",
      "列 n1 的异常值比例: 0.0000\n",
      "列 n1 使用3sigma法则处理异常值\n",
      "列 n2 的异常值比例: 0.0000\n",
      "列 n2 使用3sigma法则处理异常值\n",
      "列 n3 的异常值比例: 0.0000\n",
      "列 n3 使用3sigma法则处理异常值\n",
      "列 n4 的异常值比例: 0.0000\n",
      "列 n4 使用3sigma法则处理异常值\n",
      "列 n5 的异常值比例: 0.0000\n",
      "列 n5 使用3sigma法则处理异常值\n",
      "列 n6 的异常值比例: 0.0000\n",
      "列 n6 使用3sigma法则处理异常值\n",
      "列 n7 的异常值比例: 0.0000\n",
      "列 n7 使用3sigma法则处理异常值\n",
      "列 n8 的异常值比例: 0.0000\n",
      "列 n8 使用3sigma法则处理异常值\n",
      "列 n9 的异常值比例: 0.0000\n",
      "列 n9 使用3sigma法则处理异常值\n",
      "列 n10 的异常值比例: 0.0000\n",
      "列 n10 使用3sigma法则处理异常值\n",
      "列 n11 的异常值比例: 0.0007\n",
      "列 n11 使用3sigma法则处理异常值\n",
      "列 n12 的异常值比例: 0.0031\n",
      "列 n12 使用3sigma法则处理异常值\n",
      "列 n13 的异常值比例: 0.0000\n",
      "列 n13 使用3sigma法则处理异常值\n",
      "列 n14 的异常值比例: 0.0000\n",
      "列 n14 使用3sigma法则处理异常值\n"
     ]
    }
   ],
   "source": [
    "# 对数值型特征进行异常值处理和缺失值填充\n",
    "\n",
    "#异常值处理，使用3sigma法则和分位数法\n",
    "for col in numerical_fea:\n",
    "    if col in data_all.columns:\n",
    "        # 计算统计值用于异常值处理\n",
    "        mean_val = data_all[col].mean()\n",
    "        std_val = data_all[col].std()\n",
    "        median_val = data_all[col].median()\n",
    "        upper_limit = mean_val + 3 * std_val\n",
    "        lower_limit = mean_val - 3 * std_val\n",
    "        \n",
    "        # 记录异常值比例\n",
    "        outlier_ratio = ((data_all[col] > upper_limit) | (data_all[col] < lower_limit)).mean()\n",
    "        print(f\"列 {col} 的异常值比例: {outlier_ratio:.4f}\")\n",
    "        \n",
    "        # 对异常值进行处理：使用分位数法\n",
    "        if outlier_ratio > 0.01:  # 如果异常值比例大于1%\n",
    "            q1 = data_all[col].quantile(0.25)\n",
    "            q3 = data_all[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            \n",
    "            # 使用边界值替换异常值\n",
    "            data_all.loc[data_all[col] > upper_bound, col] = upper_bound\n",
    "            data_all.loc[data_all[col] < lower_bound, col] = lower_bound\n",
    "            print(f\"列 {col} 使用四分位法处理异常值\")\n",
    "        else:  # 如果异常值比例较小，使用3sigma法则\n",
    "            # 对异常值进行替换\n",
    "            data_all.loc[data_all[col] > upper_limit, col] = upper_limit\n",
    "            data_all.loc[data_all[col] < lower_limit, col] = lower_limit\n",
    "            print(f\"列 {col} 使用3sigma法则处理异常值\")\n",
    "        \n",
    "        # 缺失值填充，使用中位数填充\n",
    "        data_all[col] = data_all[col].fillna(median_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ead092",
   "metadata": {},
   "source": [
    "# 使用众数填充真的好吗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b79fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列 grade 使用众数 B 填充缺失值\n",
      "列 subGrade 使用众数 C1 填充缺失值\n",
      "列 employmentLength 使用众数 10 填充缺失值\n"
     ]
    }
   ],
   "source": [
    "# 对类别型特征进行缺失值填充\n",
    "for col in category_fea:\n",
    "    if col in data_all.columns:\n",
    "        # 使用众数填充\n",
    "        mode_val = data_all[col].mode()[0]\n",
    "        data_all[col] = data_all[col].fillna(mode_val)\n",
    "        print(f\"列 {col} 使用众数 {mode_val} 填充缺失值\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7096aa",
   "metadata": {},
   "source": [
    "# 这个编码方法没听说过，不知道好用不好用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c578f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 特征编码 --------\n",
    "# 对类别型特征进行编码成数字，使用LabelEncoder，方便后续模型训练\n",
    "for col in ['grade', 'subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'initialListStatus']:\n",
    "    if col in data_all.columns:\n",
    "        le = LabelEncoder()\n",
    "        data_all[col] = le.fit_transform(data_all[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2d89c",
   "metadata": {},
   "source": [
    "这段代码是在进行非常重要的一步：**特征衍生与交互特征构造**。\n",
    "\n",
    "通俗讲，它就是在“原始数据”基础上，**组合计算出新的特征变量**，以便让模型学到更多“潜在模式”，提高预测准确率。\n",
    "\n",
    "---\n",
    "\n",
    "我们来逐段解释：👇\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **目的是什么？**\n",
    "\n",
    "> **通过组合原始变量** → 构造出更具解释力的新变量（叫做“衍生特征”、“交互特征”）  \n",
    "> 让模型更容易捕捉复杂的非线性关系，提高模型性能。\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 1~16：数学衍生特征\n",
    "\n",
    "每一行都是计算新特征变量：\n",
    "\n",
    "| 特征名 | 含义 | 建模价值 |\n",
    "|--------|------|-----------|\n",
    "| `debt_to_income` | `dti` 的拷贝 | 有时方便统一使用 |\n",
    "| `debt_to_income_ratio` | 负债比 / 月收入 | 月还款压力 |\n",
    "| `installment_income_ratio` | 月供 / 月收入 | 还款能力指标 |\n",
    "| `installment_income_ratio_yearly` | 年供 / 年收入 | 另一种还款能力表示 |\n",
    "| `loan_income_ratio` | 贷款金额 / 年收入 | 财务负担 |\n",
    "| `historical_delinquency_rate` | 逾期次数 / 账户数 | 信用表现相对值 |\n",
    "| `credit_utilization_ratio` | 已用额度 / 信用额度（+1防除0） | 信用卡使用比例 |\n",
    "| `interest_to_grade` | 利率 / 等级 | 反映风险收益对应性 |\n",
    "| `util_to_loan` | 信用额度利用率 × 贷款金额 | 复合风险特征 |\n",
    "| `installment_to_loan` | 每月供款 / 总贷款 | 是否选择了高月供短期贷 |\n",
    "| `term_to_interest` | 贷款期数 × 利率 | 总利息的线索 |\n",
    "| `loan_to_term` | 总贷款 / 期数 | 每期平均额度 |\n",
    "| `fico_to_interest` | 信用分 / 利率 | 是否与信用匹配 |\n",
    "| `open_to_total_acc` | 开放账户 / 总账户 | 账户活跃度 |\n",
    "| `fico_range_diff` | 最高分 - 最低分 | 信用分数波动情况 |\n",
    "| `loan_to_fico` | 贷款 / 信用评分 | 是否贷款额度过高 |\n",
    "| `acc_to_credit_age` | 账户数 / 信用龄 | 开户频率 |\n",
    "| `loan_to_installment` | 总贷款 / 每月供款 | 贷款周期隐含特征 |\n",
    "\n",
    "这些变量都能提供模型新的“角度”去观察违约风险。\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 17. **均值编码（Mean Encoding / Target Encoding）**\n",
    "\n",
    "```python\n",
    "for col in ['grade', 'subGrade', ...]:\n",
    "    encoding_dict = train_with_target.groupby(col)['isDefault'].mean().to_dict()\n",
    "    data_all[f'{col}_mean_target'] = data_all[col].map(encoding_dict)\n",
    "```\n",
    "\n",
    "- 逻辑：对于每个类别变量，计算该类别的平均违约率作为一个新的数值特征。\n",
    "- 例如：\n",
    "  - `grade = A` → 平均违约率为 0.05\n",
    "  - `grade = G` → 平均违约率为 0.23\n",
    "- **优势**：比 one-hot 编码更紧凑，保留了目标变量的信息\n",
    "\n",
    "⚠️：此处是训练集 `train_with_target` 上提取均值，确保无数据泄露。\n",
    "\n",
    "---\n",
    "\n",
    "## 🌍 18. 与地区相关的统计特征\n",
    "\n",
    "如果数据有地区（`regionCode`）：\n",
    "- 计算该地区的平均违约率\n",
    "- 计算该地区的平均贷款金额\n",
    "\n",
    "这些特征揭示了地区经济水平或信用行为的差异。\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 19. 与贷款用途相关的统计特征\n",
    "\n",
    "如果有贷款用途（`purpose`）：\n",
    "- 每种用途的平均利率\n",
    "- 每种用途的平均贷款金额\n",
    "- 每种用途的平均违约率\n",
    "\n",
    "有助于模型理解不同贷款动机的风险差异：\n",
    "> 比如“买车”贷款比“债务整合”贷款更安全。\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结（人话版）\n",
    "\n",
    "这段代码的本质是：\n",
    "> 用数学计算、变量组合、分组统计等方法，**衍生出几十个新变量**，让模型不只是看“原始字段”，而是能学到“更深层的信息”。\n",
    "\n",
    "| 特征类型 | 方法 | 意图 |\n",
    "|----------|------|------|\n",
    "| 数学比率 | 除法、乘法 | 转化为相对值，更具稳定性 |\n",
    "| 交叉组合 | 变量相乘/相除 | 捕捉非线性关联 |\n",
    "| 均值编码 | groupby + mean | 提供类别的目标值倾向 |\n",
    "| 地区/用途统计 | 分组聚合 | 加入“群体行为”信号 |\n",
    "\n",
    "---\n",
    "\n",
    "如果你希望我：\n",
    "- 可视化这些衍生特征的分布\n",
    "- 检查这些特征和目标变量的相关性（信息增益、IV值、皮尔森系数）\n",
    "- 封装一个函数批量做这些事\n",
    "\n",
    "我可以直接帮你写 😎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73b34728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 特征交互与衍生 --------\n",
    "# 1. 负债收入比的衍生特征\n",
    "data_all['debt_to_income'] = data_all['dti']\n",
    "data_all['debt_to_income_ratio'] = data_all['dti'] / (data_all['annualIncome'] / 12)\n",
    "\n",
    "# 2. 添加还款压力比例 (分期付款金额 / 年收入)\n",
    "data_all['installment_income_ratio'] = data_all['installment'] / (data_all['annualIncome'] / 12)\n",
    "data_all['installment_income_ratio_yearly'] = data_all['installment'] * 12 / data_all['annualIncome']\n",
    "\n",
    "# 3. 添加贷款金额与年收入的比例\n",
    "data_all['loan_income_ratio'] = data_all['loanAmnt'] / data_all['annualIncome']\n",
    "\n",
    "# 4. 添加历史逾期率\n",
    "data_all['historical_delinquency_rate'] = data_all['delinquency_2years'] / (data_all['openAcc'] + 1)\n",
    "\n",
    "# 5. 添加信用卡使用率特征\n",
    "data_all['credit_utilization_ratio'] = data_all['revolBal'] / (data_all['revolUtil'] + 1)\n",
    "\n",
    "# 6. 贷款利率与等级的交互\n",
    "data_all['interest_to_grade'] = data_all['interestRate'] / (data_all['grade'] + 1)\n",
    "\n",
    "# 7. 额度利用率与贷款金额的交互\n",
    "data_all['util_to_loan'] = data_all['revolUtil'] * data_all['loanAmnt'] / 10000\n",
    "\n",
    "# 8. 分期付款与贷款金额的比率\n",
    "data_all['installment_to_loan'] = data_all['installment'] / data_all['loanAmnt']\n",
    "\n",
    "# 9. 贷款期限与利率的交互\n",
    "data_all['term_to_interest'] = data_all['term'] * data_all['interestRate'] / 100\n",
    "\n",
    "# 10. 贷款金额与期限的比率\n",
    "data_all['loan_to_term'] = data_all['loanAmnt'] / data_all['term']\n",
    "\n",
    "# 11. 信用评分与利率的交互\n",
    "data_all['fico_to_interest'] = data_all['ficoRangeLow'] / data_all['interestRate']\n",
    "\n",
    "# 12. 总账户数与开放账户数的比率\n",
    "data_all['open_to_total_acc'] = data_all['openAcc'] / (data_all['totalAcc'] + 1)\n",
    "\n",
    "# 13. 添加信用评分差异\n",
    "data_all['fico_range_diff'] = data_all['ficoRangeHigh'] - data_all['ficoRangeLow']\n",
    "\n",
    "# 14. 添加贷款额度与信用评分的交互\n",
    "data_all['loan_to_fico'] = data_all['loanAmnt'] / data_all['ficoRangeLow']\n",
    "\n",
    "# 15. 添加总账户数与信用年龄的比率\n",
    "data_all['acc_to_credit_age'] = data_all['totalAcc'] / (data_all['creditAge'] + 1)\n",
    "\n",
    "# 16. 添加贷款金额与分期付款金额的比率\n",
    "data_all['loan_to_installment'] = data_all['loanAmnt'] / data_all['installment']\n",
    "\n",
    "# 17. 添加均值编码特征\n",
    "# 确保训练数据中有isDefault列\n",
    "train_with_target = data_all[:len(train_data)].copy()\n",
    "train_with_target['isDefault'] = train_target.values\n",
    "\n",
    "for col in ['grade', 'subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'initialListStatus']:\n",
    "    # 对训练集计算每个类别的目标均值\n",
    "    if col in data_all.columns:\n",
    "        encoding_dict = train_with_target.groupby(col)['isDefault'].mean().to_dict()\n",
    "        data_all[f'{col}_mean_target'] = data_all[col].map(encoding_dict)\n",
    "\n",
    "# 18. 添加与地区相关的统计特征\n",
    "if 'regionCode' in data_all.columns:\n",
    "    # 每个regionCode的违约率\n",
    "    region_default = train_with_target.groupby('regionCode')['isDefault'].mean()\n",
    "    data_all['region_default_rate'] = data_all['regionCode'].map(region_default)\n",
    "    \n",
    "    # 每个regionCode的平均贷款金额\n",
    "    region_loan = data_all.groupby('regionCode')['loanAmnt'].mean()\n",
    "    data_all['region_avg_loan'] = data_all['regionCode'].map(region_loan)\n",
    "\n",
    "# 19. 添加贷款目的相关的统计特征\n",
    "if 'purpose' in data_all.columns:\n",
    "    # 每种目的的平均利率\n",
    "    purpose_interest = data_all.groupby('purpose')['interestRate'].mean()\n",
    "    data_all['purpose_avg_interest'] = data_all['purpose'].map(purpose_interest)\n",
    "    \n",
    "    # 每种目的的平均贷款金额\n",
    "    purpose_loan = data_all.groupby('purpose')['loanAmnt'].mean()\n",
    "    data_all['purpose_avg_loan'] = data_all['purpose'].map(purpose_loan)\n",
    "    \n",
    "    # 每种目的的违约率\n",
    "    purpose_default = train_with_target.groupby('purpose')['isDefault'].mean()\n",
    "    data_all['purpose_default_rate'] = data_all['purpose'].map(purpose_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890a8a8",
   "metadata": {},
   "source": [
    "# 计算特征值之间的相关系数，如果相关系数大，就移除一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbc31338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 特征选择 ===================== #\n",
    "# 移除高度相关特征\n",
    "\n",
    "def correlation_selector(X, threshold=0.8):\n",
    "    try:\n",
    "        corr_matrix = X.corr().abs()\n",
    "        # 确保使用numpy.triu正确创建三角矩阵掩码\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "        return to_drop\n",
    "    except Exception as e:\n",
    "        print(f\"相关性分析失败: {str(e)}\")\n",
    "        # 如果失败，返回空列表\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b19a48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离训练集和测试集\n",
    "train = data_all[:len(train_data)]\n",
    "test = data_all[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "505988bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高相关性特征数量: 23\n",
      "高相关性特征: ['installment', 'grade', 'subGrade', 'ficoRangeHigh', 'n3', 'n9', 'n10', 'issueDateQuarter', 'issueDateDT', 'earliesCreditLineYear', 'debt_to_income', 'installment_income_ratio_yearly', 'loan_income_ratio', 'historical_delinquency_rate', 'loan_to_term', 'loan_to_fico', 'loan_to_installment', 'grade_mean_target', 'subGrade_mean_target', 'verificationStatus_mean_target', 'initialListStatus_mean_target', 'purpose_avg_interest', 'purpose_default_rate']\n"
     ]
    }
   ],
   "source": [
    "# 检查高相关性特征\n",
    "try:\n",
    "    high_corr_features = correlation_selector(train.select_dtypes(include=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']), 0.90)\n",
    "    print(f\"高相关性特征数量: {len(high_corr_features)}\")\n",
    "    print(f\"高相关性特征: {high_corr_features}\")\n",
    "    \n",
    "    # 去除高相关性特征\n",
    "    data_all = data_all.drop(high_corr_features, axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"去除高相关性特征失败: {str(e)}\")\n",
    "    # 不做任何删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49eb173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新分离训练集和测试集\n",
    "train = data_all[:len(train_data)]\n",
    "test = data_all[len(train_data):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679fa492",
   "metadata": {},
   "source": [
    "# 对于非树模型，将数据进行标准化，标准化为均值为0，方差为1的正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9dda7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数值特征 (仅针对非树模型)\n",
    "numeric_features_for_scaling = [col for col in numerical_fea if col in train.columns]\n",
    "scaler = StandardScaler()\n",
    "train_scaled = train.copy()\n",
    "test_scaled = test.copy()\n",
    "train_scaled[numeric_features_for_scaling] = scaler.fit_transform(train[numeric_features_for_scaling])\n",
    "test_scaled[numeric_features_for_scaling] = scaler.transform(test[numeric_features_for_scaling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f5d9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始模型训练与调参...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================== 模型训练与调参 ===================== #\n",
    "print('='*80)\n",
    "print('开始模型训练与调参...')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d5b09",
   "metadata": {},
   "source": [
    "这段代码是在进行模型训练前的一项关键操作：**数据集划分 + 特征值预处理（处理异常值、无穷值、缺失值）**。我们来一块块拆解讲清楚。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 第一部分：划分训练集和验证集\n",
    "```python\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train, train_target, test_size=0.2, random_state=42, stratify=train_target\n",
    ")\n",
    "```\n",
    "\n",
    "### ✅ 作用\n",
    "- 将你的训练数据（`train`）和目标标签（`train_target`）**划分为训练集和验证集**。\n",
    "- `test_size=0.2` 表示 20% 的数据将作为验证集。\n",
    "- `stratify=train_target` 表示使用**分层抽样**，保持训练集和验证集中类别分布一致（用于分类任务，防止类不平衡）。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 第二部分：处理无穷大值和异常值\n",
    "\n",
    "```python\n",
    "for col in X_train.columns:\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 🧪 为什么这么做？\n",
    "\n",
    "模型训练前必须确保数据**干净合理**：\n",
    "- 没有 `inf`（无穷值）或 `nan`（空值）\n",
    "- 没有极端异常值（比如特征值是 `1e20` 或 `-1e20` 这种极大极小数）\n",
    "- 否则模型可能不收敛、预测不稳定，甚至直接报错\n",
    "\n",
    "---\n",
    "\n",
    "### 🧼 清洗步骤一：处理 `inf` 和 `-inf`\n",
    "```python\n",
    "X_train[col] = X_train[col].replace([np.inf, -np.inf], np.nan)\n",
    "```\n",
    "- 将所有正无穷和负无穷替换成 `np.nan`，为下一步的缺失值填充做准备。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧼 清洗步骤二：处理异常大值\n",
    "```python\n",
    "upper_bound = X_train[col].quantile(0.99)\n",
    "lower_bound = X_train[col].quantile(0.01)\n",
    "\n",
    "if upper_bound > 1e8:\n",
    "    X_train[col] = X_train[col].clip(upper=upper_bound)\n",
    "```\n",
    "- 计算第1% 和 第99% 分位数（即保留中间98%的数据）\n",
    "- 如果第99%的值已经非常大（如大于1亿），说明该特征分布很偏，可能有极端异常值\n",
    "- 用 `clip()` 限制最大值，不让极端值影响模型训练\n",
    "\n",
    "---\n",
    "\n",
    "### 🧼 清洗步骤三：填充缺失值\n",
    "```python\n",
    "X_train[col] = X_train[col].fillna(X_train[col].median())\n",
    "```\n",
    "- 对缺失值 `NaN` 进行填充\n",
    "- 使用训练集的 **中位数**，这样在填充时不会泄露验证集或测试集的信息\n",
    "- 保持数据分布稳定，适合大多数模型\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结作用：\n",
    "\n",
    "| 步骤 | 操作 | 目的 |\n",
    "|------|------|------|\n",
    "| 1 | `train_test_split()` | 拆分训练集和验证集，确保泛化评估 |\n",
    "| 2 | `replace([inf, -inf], NaN)` | 清除非法值 |\n",
    "| 3 | `clip()` | 裁剪异常大值，防止模型受到极端干扰 |\n",
    "| 4 | `fillna()` | 填充缺失值，避免训练时报错 |\n",
    "\n",
    "---\n",
    "\n",
    "这段代码是非常“工程实践化”的处理方式。模型能不能训好，很多时候就看这些 **干净数据预处理环节**做得细不细了。\n",
    "\n",
    "---\n",
    "\n",
    "如果你希望我把这个过程**封装成函数**、或**做成自动化预处理模块**，或者帮你接入 `Pipeline`，我也可以帮你写出来～要不要？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5cd3c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 划分训练集和验证集\n",
      "训练集大小: (640000, 59), 验证集大小: (160000, 59)\n",
      "\n",
      "2. 处理无穷大值和异常值\n",
      "数据预处理完成\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和验证集\n",
    "print('1. 划分训练集和验证集')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train, train_target, test_size=0.2, random_state=42, stratify=train_target\n",
    ")\n",
    "print(f'训练集大小: {X_train.shape}, 验证集大小: {X_val.shape}')\n",
    "\n",
    "# 处理无穷大值和过大值\n",
    "print('\\n2. 处理无穷大值和异常值')\n",
    "# 在模型训练前替换inf和极大值\n",
    "for col in X_train.columns:\n",
    "    # 替换无穷大值\n",
    "    X_train[col] = X_train[col].replace([np.inf, -np.inf], np.nan)\n",
    "    X_val[col] = X_val[col].replace([np.inf, -np.inf], np.nan)\n",
    "    test[col] = test[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 检查并替换极大或极小的值\n",
    "    upper_bound = X_train[col].quantile(0.99)\n",
    "    lower_bound = X_train[col].quantile(0.01)\n",
    "    \n",
    "    # 如果上限非常大，用更合理的值替代\n",
    "    if upper_bound > 1e8:\n",
    "        X_train[col] = X_train[col].clip(upper=upper_bound)\n",
    "        X_val[col] = X_val[col].clip(upper=upper_bound)\n",
    "        test[col] = test[col].clip(upper=upper_bound)\n",
    "    \n",
    "    # 填充缺失值\n",
    "    X_train[col] = X_train[col].fillna(X_train[col].median())\n",
    "    X_val[col] = X_val[col].fillna(X_train[col].median())\n",
    "    test[col] = test[col].fillna(X_train[col].median())\n",
    "\n",
    "print('数据预处理完成')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfed90",
   "metadata": {},
   "source": [
    "# 这段代码定义了一个用于评估二分类模型性能的函数，它的核心是计算 AUC 值（ROC曲线下面积），这是衡量模型分类效果的一种常用且稳定的指标，尤其适用于类别不平衡的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cda0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "def model_evaluation(model, X, y):\n",
    "    y_pred_prob = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, y_pred_prob)\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "245d5c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. 训练LightGBM模型...\n",
      "--------------------------------------------------\n",
      "开始训练LightGBM模型...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's auc: 0.735691\n",
      "LightGBM模型训练完成\n"
     ]
    }
   ],
   "source": [
    "# 模型1: LightGBM\n",
    "print('\\n3. 训练LightGBM模型...')\n",
    "print('-'*50)\n",
    "lgb_params = {\n",
    "    'objective': 'binary',              # 二分类任务\n",
    "    'boosting_type': 'gbdt',            # 使用梯度提升树（默认）\n",
    "    'metric': 'auc',                    # 使用 AUC 作为评估指标\n",
    "    'n_estimators': 1000,               # 最多训练1000棵树（但会早停）\n",
    "    'learning_rate': 0.05,              # 学习率（每棵树的权重缩小因子）\n",
    "    'max_depth': 7,                     # 每棵树的最大深度\n",
    "    'num_leaves': 31,                   # 每棵树的叶子节点数\n",
    "    'subsample': 0.8,                   # 每棵树训练时使用80%的样本（防过拟合）\n",
    "    'colsample_bytree': 0.8,            # 每棵树训练时使用80%的特征\n",
    "    'min_child_weight': 5,              # 控制叶子节点的最小样本权重和（防过拟合）\n",
    "    'min_child_samples': 30,            # 控制叶子节点的最小样本数\n",
    "    'min_split_gain': 0.01,             # 控制分裂的最小增益\n",
    "    'reg_alpha': 0.3,                   # L1 正则化\n",
    "    'reg_lambda': 0.3,                  # L2 正则化\n",
    "    'random_state': 42,                 # 固定随机种子，结果可复现\n",
    "    'n_jobs': -1,                       # 使用所有CPU核心\n",
    "    'verbosity': -1                     # 控制训练过程输出（-1表示静默）\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "# 最新的LightGBM版本中，早停参数通过callbacks参数传递\n",
    "print('开始训练LightGBM模型...')\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100)]  # 不再使用verbose参数\n",
    ")\n",
    "print('LightGBM模型训练完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f1787d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:19:57,672] A new study created in memory with name: no-name-13b6daad-f1cd-4796-bf7c-0e21f4009c2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 使用Optuna开始调参LightGBM...\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:20:02,983] Trial 0 finished with value: 0.7165399922830881 and parameters: {'learning_rate': 0.0017031439070567928, 'num_leaves': 111, 'max_depth': 11, 'min_child_samples': 93, 'min_child_weight': 4.7507709370859335, 'subsample': 0.9392386756707851, 'colsample_bytree': 0.408248312517427, 'reg_alpha': 0.03577004231144713, 'reg_lambda': 0.013861710427355841, 'min_split_gain': 0.4129507061932446}. Best is trial 0 with value: 0.7165399922830881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.71654\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's auc: 0.73527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:20:29,291] Trial 1 finished with value: 0.7352703686292037 and parameters: {'learning_rate': 0.04925539083910025, 'num_leaves': 44, 'max_depth': 4, 'min_child_samples': 25, 'min_child_weight': 1.20305895094142, 'subsample': 0.7034553962700787, 'colsample_bytree': 0.7723858341601126, 'reg_alpha': 0.001761020804562959, 'reg_lambda': 0.004270650437107693, 'min_split_gain': 0.5896491629088436}. Best is trial 1 with value: 0.7352703686292037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's auc: 0.712013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:20:56,655] Trial 2 finished with value: 0.7120127124208862 and parameters: {'learning_rate': 0.0025384798912460745, 'num_leaves': 114, 'max_depth': 3, 'min_child_samples': 41, 'min_child_weight': 3.123019391616099, 'subsample': 0.6117843785404178, 'colsample_bytree': 0.5009709700076532, 'reg_alpha': 0.023714912418445793, 'reg_lambda': 1.5251213406417203, 'min_split_gain': 0.16178594919127076}. Best is trial 1 with value: 0.7352703686292037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[809]\tvalid_0's auc: 0.735834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:23,728] Trial 3 finished with value: 0.7358336675573004 and parameters: {'learning_rate': 0.04349917508817114, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 12, 'min_child_weight': 0.013914085896640532, 'subsample': 0.4272822291217523, 'colsample_bytree': 0.5282906446753931, 'reg_alpha': 0.00184782592771305, 'reg_lambda': 0.016429400614128564, 'min_split_gain': 0.043118045136198324}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:28,276] Trial 4 finished with value: 0.733117329553107 and parameters: {'learning_rate': 0.23427031765456646, 'num_leaves': 55, 'max_depth': 10, 'min_child_samples': 88, 'min_child_weight': 2.626270546359943, 'subsample': 0.7930266669748168, 'colsample_bytree': 0.7107869348833828, 'reg_alpha': 0.0031362568555826933, 'reg_lambda': 0.03071327610137785, 'min_split_gain': 0.44860725611708097}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.733117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:29,089] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:29,942] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:30,812] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:31,709] Trial 8 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's auc: 0.734666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:42,264] Trial 9 finished with value: 0.7346657550978092 and parameters: {'learning_rate': 0.07845418157775196, 'num_leaves': 121, 'max_depth': 11, 'min_child_samples': 43, 'min_child_weight': 0.001686334483108679, 'subsample': 0.967555900305187, 'colsample_bytree': 0.6466571747633436, 'reg_alpha': 0.00759657672501159, 'reg_lambda': 0.07034185104661038, 'min_split_gain': 0.08972257020445518}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.732235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:47,255] Trial 10 finished with value: 0.732235382437441 and parameters: {'learning_rate': 0.22285387949959118, 'num_leaves': 76, 'max_depth': 7, 'min_child_samples': 64, 'min_child_weight': 0.017925413027505513, 'subsample': 0.4026848760159921, 'colsample_bytree': 0.5638192193377669, 'reg_alpha': 0.2021280673152125, 'reg_lambda': 0.001004703698463974, 'min_split_gain': 0.3020652020290301}. Best is trial 3 with value: 0.7358336675573004.\n",
      "[I 2025-04-15 21:21:48,117] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:49,018] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:49,891] Trial 13 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:21:55,269] Trial 14 pruned. Trial was pruned at iteration 74.\n",
      "[I 2025-04-15 21:21:56,189] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:57,049] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:57,961] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:58,829] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:21:59,857] Trial 19 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:00,862] Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.73464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:10,830] Trial 21 finished with value: 0.7346404571033522 and parameters: {'learning_rate': 0.08569759801054834, 'num_leaves': 141, 'max_depth': 12, 'min_child_samples': 39, 'min_child_weight': 0.0020913771694108948, 'subsample': 0.99196902466155, 'colsample_bytree': 0.6376321419263474, 'reg_alpha': 0.00883493757794046, 'reg_lambda': 0.04458884283449809, 'min_split_gain': 0.11446921264501742}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.7336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:18,106] Trial 22 finished with value: 0.7335997969973342 and parameters: {'learning_rate': 0.13241587772931684, 'num_leaves': 122, 'max_depth': 12, 'min_child_samples': 43, 'min_child_weight': 0.001007958469582591, 'subsample': 0.8524320295015175, 'colsample_bytree': 0.6093233905809211, 'reg_alpha': 0.0028687554010721115, 'reg_lambda': 0.24420582707036131, 'min_split_gain': 0.1509261868550354}. Best is trial 3 with value: 0.7358336675573004.\n",
      "[I 2025-04-15 21:22:19,253] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:20,519] Trial 24 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:21,477] Trial 25 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:22,392] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:23,308] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:24,236] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:25,408] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:26,577] Trial 30 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's auc: 0.73467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:38,113] Trial 31 finished with value: 0.7346702381535699 and parameters: {'learning_rate': 0.08167359649442191, 'num_leaves': 135, 'max_depth': 12, 'min_child_samples': 38, 'min_child_weight': 0.002215197955280905, 'subsample': 0.9838981255147466, 'colsample_bytree': 0.6083295569871157, 'reg_alpha': 0.009023598725930403, 'reg_lambda': 0.12745080885861435, 'min_split_gain': 0.11301375171705763}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:39,280] Trial 32 pruned. Trial was pruned at iteration 4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.733894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:45,240] Trial 33 finished with value: 0.7338939699849024 and parameters: {'learning_rate': 0.16154160651200325, 'num_leaves': 109, 'max_depth': 10, 'min_child_samples': 41, 'min_child_weight': 0.0020402834552025453, 'subsample': 0.8921018632596649, 'colsample_bytree': 0.5091594553565657, 'reg_alpha': 0.004337644146880804, 'reg_lambda': 1.5847449047486155, 'min_split_gain': 0.1257664032258705}. Best is trial 3 with value: 0.7358336675573004.\n",
      "[I 2025-04-15 21:22:46,279] Trial 34 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:47,500] Trial 35 pruned. Trial was pruned at iteration 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.734132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:56,519] Trial 36 finished with value: 0.7341318016084779 and parameters: {'learning_rate': 0.09237056021038907, 'num_leaves': 133, 'max_depth': 12, 'min_child_samples': 15, 'min_child_weight': 0.0017187263061868607, 'subsample': 0.9512444951664923, 'colsample_bytree': 0.6012176344206386, 'reg_alpha': 0.01850299376147343, 'reg_lambda': 0.12259632805988117, 'min_split_gain': 0.25568268163271485}. Best is trial 3 with value: 0.7358336675573004.\n",
      "[I 2025-04-15 21:22:57,446] Trial 37 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:22:58,606] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:22:59,498] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:23:00,571] Trial 40 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.734787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:23:10,886] Trial 41 finished with value: 0.7347866760430536 and parameters: {'learning_rate': 0.09199315760545437, 'num_leaves': 145, 'max_depth': 12, 'min_child_samples': 37, 'min_child_weight': 0.002408483644795843, 'subsample': 0.9833703892001472, 'colsample_bytree': 0.6366416906248716, 'reg_alpha': 0.008727881489997424, 'reg_lambda': 0.03767419287322962, 'min_split_gain': 0.11721732763020229}. Best is trial 3 with value: 0.7358336675573004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:23:15,300] Trial 42 pruned. Trial was pruned at iteration 69.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:23:23,154] Trial 43 pruned. Trial was pruned at iteration 134.\n",
      "[I 2025-04-15 21:23:24,173] Trial 44 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:23:25,243] Trial 45 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 21:23:26,173] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:23:27,093] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:23:27,998] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-15 21:23:28,998] Trial 49 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "\n",
      "🎯 Optuna调参完成！\n",
      "Best AUC: 0.7358336675573004\n",
      "Best Hyperparameters:\n",
      "  learning_rate: 0.04349917508817114\n",
      "  num_leaves: 48\n",
      "  max_depth: 6\n",
      "  min_child_samples: 12\n",
      "  min_child_weight: 0.013914085896640532\n",
      "  subsample: 0.4272822291217523\n",
      "  colsample_bytree: 0.5282906446753931\n",
      "  reg_alpha: 0.00184782592771305\n",
      "  reg_lambda: 0.016429400614128564\n",
      "  min_split_gain: 0.043118045136198324\n",
      "\n",
      "🏁 使用最优参数重新训练LightGBM模型...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[809]\tvalid_0's auc: 0.735834\n",
      "✅ 最终模型训练完成！\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ===================== Optuna 调参目标函数 ===================== #\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "\n",
    "        # 需要调参的部分 ↓↓↓\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**param, n_estimators=1000)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            LightGBMPruningCallback(trial, 'auc')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    return auc\n",
    "\n",
    "\n",
    "# ===================== 开始调参 ===================== #\n",
    "print('\\n🚀 使用Optuna开始调参LightGBM...')\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # 可以调成更大的值，比如100\n",
    "\n",
    "# ===================== 输出最优参数 ===================== #\n",
    "print('\\n🎯 Optuna调参完成！')\n",
    "print('Best AUC:', study.best_value)\n",
    "print('Best Hyperparameters:')\n",
    "for k, v in study.best_params.items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "# ===================== 用最优参数训练最终模型 ===================== #\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "print('\\n🏁 使用最优参数重新训练LightGBM模型...')\n",
    "final_lgbm_model = lgb.LGBMClassifier(**best_params, n_estimators=1000)\n",
    "final_lgbm_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n",
    "\n",
    "print('✅ 最终模型训练完成！')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb744473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_features = lgb_importance.head(20)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['feature'][::-1], top_features['importance'][::-1])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Top 20 Important Features (Optuna-tuned Model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3103e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optuna优化后的LightGBM验证集AUC: 0.7358\n"
     ]
    }
   ],
   "source": [
    "final_lgbm_auc = model_evaluation(final_lgbm_model, X_val, y_val)\n",
    "print(f'✅ Optuna优化后的LightGBM验证集AUC: {final_lgbm_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "697cd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. 训练XGBoost模型...\n",
      "--------------------------------------------------\n",
      "开始训练XGBoost模型...\n",
      "[0]\tvalidation_0-auc:0.70339\tvalidation_1-auc:0.70142\n",
      "[100]\tvalidation_0-auc:0.73731\tvalidation_1-auc:0.72935\n",
      "[200]\tvalidation_0-auc:0.74709\tvalidation_1-auc:0.73298\n",
      "[300]\tvalidation_0-auc:0.75424\tvalidation_1-auc:0.73456\n",
      "[400]\tvalidation_0-auc:0.76014\tvalidation_1-auc:0.73517\n",
      "[500]\tvalidation_0-auc:0.76547\tvalidation_1-auc:0.73561\n",
      "[600]\tvalidation_0-auc:0.77059\tvalidation_1-auc:0.73583\n",
      "[700]\tvalidation_0-auc:0.77547\tvalidation_1-auc:0.73603\n",
      "[800]\tvalidation_0-auc:0.78013\tvalidation_1-auc:0.73606\n",
      "[857]\tvalidation_0-auc:0.78270\tvalidation_1-auc:0.73594\n",
      "XGBoost模型训练完成\n"
     ]
    }
   ],
   "source": [
    "# 模型2: XGBoost\n",
    "print('\\n4. 训练XGBoost模型...')\n",
    "print('-'*50)\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',      # 二分类任务，输出为概率\n",
    "    'learning_rate': 0.05,               # 学习率，控制每棵树对最终结果的影响\n",
    "    'max_depth': 6,                      # 决策树最大深度，限制模型复杂度\n",
    "    'min_child_weight': 3,               # 子节点所需的最小样本权重和，控制过拟合\n",
    "    'gamma': 0.1,                        # 分裂所需的最小损失下降，越大越保守\n",
    "    'subsample': 0.8,                    # 每棵树训练时随机采样的样本比例\n",
    "    'colsample_bytree': 0.8,             # 每棵树训练时随机采样的特征比例\n",
    "    'scale_pos_weight': 1,               # 类别不平衡时的正类权重，1 表示样本均衡\n",
    "    'reg_alpha': 0.1,                    # L1正则化项系数（控制特征选择）\n",
    "    'reg_lambda': 0.1,                   # L2正则化项系数（防止权重过大）\n",
    "    'n_estimators': 1000,                # 最多拟合的树数量（迭代次数上限）\n",
    "    'random_state': 42,                  # 随机种子，保证结果可复现\n",
    "    'n_jobs': -1,                        # 使用全部CPU核心进行训练\n",
    "    'eval_metric': 'auc',               # 使用AUC作为评估指标\n",
    "    'verbosity': 0,                      # 控制日志输出级别（0=只输出警告）\n",
    "    'early_stopping_rounds': 100,        # 如果验证集AUC 100轮未提升，则提前停止\n",
    "    'missing': np.nan                    # 指定缺失值的占位符（XGBoost自动处理）\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "print('开始训练XGBoost模型...')\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],  # 用训练集和验证集评估性能（训练集必须放前面以启用早停）\n",
    "    verbose=100  # 每100轮打印一次训练进度\n",
    ")\n",
    "\n",
    "print('XGBoost模型训练完成')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b336c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost验证集AUC: 0.7361\n"
     ]
    }
   ],
   "source": [
    "# 评估XGBoost模型\n",
    "xgb_auc = model_evaluation(xgb_model, X_val, y_val)\n",
    "print(f'XGBoost验证集AUC: {xgb_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "994ba7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. 训练CatBoost模型...\n",
      "--------------------------------------------------\n",
      "开始训练CatBoost模型...\n",
      "0:\ttest: 0.6983230\tbest: 0.6983230 (0)\ttotal: 231ms\tremaining: 3m 51s\n",
      "100:\ttest: 0.7255135\tbest: 0.7255135 (100)\ttotal: 7.22s\tremaining: 1m 4s\n",
      "200:\ttest: 0.7300976\tbest: 0.7300976 (200)\ttotal: 13.9s\tremaining: 55.3s\n",
      "300:\ttest: 0.7320580\tbest: 0.7320580 (300)\ttotal: 20.4s\tremaining: 47.5s\n",
      "400:\ttest: 0.7332291\tbest: 0.7332291 (400)\ttotal: 27.3s\tremaining: 40.8s\n",
      "500:\ttest: 0.7340301\tbest: 0.7340301 (500)\ttotal: 34.3s\tremaining: 34.1s\n",
      "600:\ttest: 0.7346401\tbest: 0.7346401 (600)\ttotal: 41s\tremaining: 27.2s\n",
      "700:\ttest: 0.7350226\tbest: 0.7350226 (700)\ttotal: 47.6s\tremaining: 20.3s\n",
      "800:\ttest: 0.7354252\tbest: 0.7354288 (799)\ttotal: 54.1s\tremaining: 13.4s\n",
      "900:\ttest: 0.7356365\tbest: 0.7356365 (900)\ttotal: 1m\tremaining: 6.63s\n",
      "999:\ttest: 0.7358202\tbest: 0.7358311 (982)\ttotal: 1m 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7358310536\n",
      "bestIteration = 982\n",
      "\n",
      "Shrink model to first 983 iterations.\n",
      "CatBoost模型训练完成\n"
     ]
    }
   ],
   "source": [
    "# 模型3: CatBoost\n",
    "print('\\n5. 训练CatBoost模型...')\n",
    "print('-'*50)\n",
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'min_child_samples': 20,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_strength': 0.1,\n",
    "    'bagging_temperature': 1,\n",
    "    'iterations': 1000,\n",
    "    'random_seed': 42,\n",
    "    'thread_count': -1,\n",
    "    'verbose': 100  # 设置为100以每100次迭代显示一次进度\n",
    "}\n",
    "\n",
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "print('开始训练CatBoost模型...')\n",
    "cat_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=100,  # 早停参数在fit方法中指定\n",
    "    use_best_model=True,  # 确保使用最佳模型\n",
    "    verbose=100  # 每100次迭代显示一次进度\n",
    ")\n",
    "print('CatBoost模型训练完成')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76cded67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost验证集AUC: 0.7358\n"
     ]
    }
   ],
   "source": [
    "# 评估CatBoost模型\n",
    "cat_auc = model_evaluation(cat_model, X_val, y_val)\n",
    "print(f'CatBoost验证集AUC: {cat_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cadf81cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. 训练随机森林模型...\n",
      "--------------------------------------------------\n",
      "开始训练随机森林模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林模型训练完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "# 模型4: 随机森林\n",
    "print('\\n6. 训练随机森林模型...')\n",
    "print('-'*50)\n",
    "rf_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 5,\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': 1  # 显示训练进度\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "print('开始训练随机森林模型...')\n",
    "rf_model.fit(X_train, y_train)\n",
    "print('随机森林模型训练完成')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de706756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林验证集AUC: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# 评估随机森林模型\n",
    "rf_auc = model_evaluation(rf_model, X_val, y_val)\n",
    "print(f'随机森林验证集AUC: {rf_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f63cb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "开始模型融合...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================== 模型融合 ===================== #\n",
    "print('\\n='*80)\n",
    "print('开始模型融合...')\n",
    "print('='*80)\n",
    "\n",
    "# 方法1: 简单平均\n",
    "def simple_averaging(models, test):\n",
    "    print('计算简单平均预测...')\n",
    "    predictions = []\n",
    "    for i, model in enumerate(models):\n",
    "        pred = model.predict_proba(test)[:, 1]\n",
    "        predictions.append(pred)\n",
    "    return np.mean(np.array(predictions), axis=0)\n",
    "\n",
    "# 方法2: 加权平均 (根据验证集上的性能加权)\n",
    "def weighted_averaging(models, weights, test):\n",
    "    print('计算加权平均预测...')\n",
    "    predictions = []\n",
    "    for i, model in enumerate(models):\n",
    "        pred = model.predict_proba(test)[:, 1]\n",
    "        predictions.append(pred * weights[i])\n",
    "    return np.sum(np.array(predictions), axis=0) / np.sum(weights)\n",
    "\n",
    "# 方法3: Stacking (使用5折交叉验证生成训练集的meta特征)\n",
    "def stacking(base_models, meta_model, X, y, test, n_folds=5):\n",
    "    print('执行Stacking集成...')\n",
    "    # 生成元特征\n",
    "    meta_features_train = np.zeros((X.shape[0], len(base_models)))\n",
    "    meta_features_test = np.zeros((test.shape[0], len(base_models)))\n",
    "    \n",
    "    # K折交叉验证\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 对每个基础模型\n",
    "    for i, model in enumerate(base_models):\n",
    "        print(f'处理第 {i+1}/{len(base_models)} 个基础模型...')\n",
    "        # 对测试集的预测\n",
    "        try:\n",
    "            # XGBoost模型特殊处理 - 使用固定迭代次数而不使用早停\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                print(\"  检测到XGBoost模型，使用固定迭代次数1000...\")\n",
    "                # 创建一个没有early_stopping的XGBoost模型副本\n",
    "                xgb_clone = xgb.XGBClassifier(\n",
    "                    objective='binary:logistic',\n",
    "                    learning_rate=0.05,\n",
    "                    max_depth=6,\n",
    "                    min_child_weight=3,\n",
    "                    gamma=0.1,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    scale_pos_weight=1,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    n_estimators=1000,  # 使用固定迭代次数1000\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                    verbosity=0\n",
    "                )\n",
    "                xgb_clone.fit(X, y)\n",
    "                meta_features_test[:, i] = xgb_clone.predict_proba(test)[:, 1]\n",
    "                \n",
    "                # 对训练集进行交叉验证预测\n",
    "                for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "                    print(f'  处理折 {fold+1}/{n_folds}')\n",
    "                    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "                    y_train_fold = y.iloc[train_index]\n",
    "                    \n",
    "                    xgb_clone.fit(X_train_fold, y_train_fold)\n",
    "                    meta_features_train[val_index, i] = xgb_clone.predict_proba(X_val_fold)[:, 1]\n",
    "            else:\n",
    "                # 其他模型正常处理\n",
    "                model.fit(X, y)\n",
    "                meta_features_test[:, i] = model.predict_proba(test)[:, 1]\n",
    "                \n",
    "                # 对训练集进行交叉验证预测\n",
    "                for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "                    print(f'  处理折 {fold+1}/{n_folds}')\n",
    "                    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "                    y_train_fold = y.iloc[train_index]\n",
    "                    \n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    meta_features_train[val_index, i] = model.predict_proba(X_val_fold)[:, 1]\n",
    "        except Exception as e:\n",
    "            print(f\"模型 {i} 出现错误: {str(e)}\")\n",
    "            # 如果模型预测失败，使用该模型在验证集上的平均预测值填充\n",
    "            meta_features_train[:, i] = y.mean()\n",
    "            meta_features_test[:, i] = y.mean()\n",
    "    \n",
    "    # 训练元模型\n",
    "    print('训练元模型...')\n",
    "    meta_model.fit(meta_features_train, y)\n",
    "    \n",
    "    # 使用元模型预测测试集\n",
    "    final_predictions = meta_model.predict_proba(meta_features_test)[:, 1]\n",
    "    print('Stacking完成')\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "468c7634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "各模型AUC:\n",
      "LightGBM AUC: 0.7358\n",
      "XGBoost AUC: 0.7361\n",
      "CatBoost AUC: 0.7358\n",
      "RandomForest AUC: 0.7150\n"
     ]
    }
   ],
   "source": [
    "# 计算AUC\n",
    "models = [final_lgbm_model, xgb_model, cat_model, rf_model]\n",
    "val_aucs = [final_lgbm_auc, xgb_auc, cat_auc, rf_auc]\n",
    "# 打印每个模型的AUC\n",
    "print('\\n各模型AUC:')\n",
    "for model_name, auc in zip(['LightGBM', 'XGBoost', 'CatBoost', 'RandomForest'], val_aucs):\n",
    "    print(f'{model_name} AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0abbe162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算简单平均预测...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "简单平均预测完成\n",
      "计算加权平均预测...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加权平均预测完成\n",
      "执行Stacking集成...\n",
      "处理第 1/4 个基础模型...\n",
      "  处理折 1/5\n",
      "  处理折 2/5\n",
      "  处理折 3/5\n",
      "  处理折 4/5\n",
      "  处理折 5/5\n",
      "处理第 2/4 个基础模型...\n",
      "  检测到XGBoost模型，使用固定迭代次数1000...\n",
      "  处理折 1/5\n",
      "  处理折 2/5\n",
      "  处理折 3/5\n",
      "  处理折 4/5\n",
      "  处理折 5/5\n",
      "处理第 3/4 个基础模型...\n",
      "0:\ttotal: 69.9ms\tremaining: 1m 9s\n",
      "100:\ttotal: 5.97s\tremaining: 53.1s\n",
      "200:\ttotal: 11.7s\tremaining: 46.4s\n",
      "300:\ttotal: 17.4s\tremaining: 40.3s\n",
      "400:\ttotal: 23s\tremaining: 34.3s\n",
      "500:\ttotal: 28.7s\tremaining: 28.6s\n",
      "600:\ttotal: 34.3s\tremaining: 22.8s\n",
      "700:\ttotal: 40s\tremaining: 17.1s\n",
      "800:\ttotal: 45.8s\tremaining: 11.4s\n",
      "900:\ttotal: 51.4s\tremaining: 5.65s\n",
      "999:\ttotal: 57.3s\tremaining: 0us\n",
      "  处理折 1/5\n",
      "0:\ttotal: 49.6ms\tremaining: 49.5s\n",
      "100:\ttotal: 4.74s\tremaining: 42.2s\n",
      "200:\ttotal: 9.24s\tremaining: 36.7s\n",
      "300:\ttotal: 14s\tremaining: 32.4s\n",
      "400:\ttotal: 18.5s\tremaining: 27.6s\n",
      "500:\ttotal: 23.1s\tremaining: 23s\n",
      "600:\ttotal: 27.7s\tremaining: 18.4s\n",
      "700:\ttotal: 32.2s\tremaining: 13.7s\n",
      "800:\ttotal: 36.6s\tremaining: 9.1s\n",
      "900:\ttotal: 41.2s\tremaining: 4.52s\n",
      "999:\ttotal: 45.9s\tremaining: 0us\n",
      "  处理折 2/5\n",
      "0:\ttotal: 52.6ms\tremaining: 52.6s\n",
      "100:\ttotal: 5.19s\tremaining: 46.2s\n",
      "200:\ttotal: 10.1s\tremaining: 40.1s\n",
      "300:\ttotal: 14.9s\tremaining: 34.7s\n",
      "400:\ttotal: 19.8s\tremaining: 29.6s\n",
      "500:\ttotal: 24.6s\tremaining: 24.5s\n",
      "600:\ttotal: 29.2s\tremaining: 19.4s\n",
      "700:\ttotal: 33.8s\tremaining: 14.4s\n",
      "800:\ttotal: 38.4s\tremaining: 9.54s\n",
      "900:\ttotal: 42.9s\tremaining: 4.71s\n",
      "999:\ttotal: 47.4s\tremaining: 0us\n",
      "  处理折 3/5\n",
      "0:\ttotal: 51.8ms\tremaining: 51.8s\n",
      "100:\ttotal: 4.81s\tremaining: 42.8s\n",
      "200:\ttotal: 9.38s\tremaining: 37.3s\n",
      "300:\ttotal: 14.2s\tremaining: 33s\n",
      "400:\ttotal: 18.9s\tremaining: 28.3s\n",
      "500:\ttotal: 23.4s\tremaining: 23.4s\n",
      "600:\ttotal: 28s\tremaining: 18.6s\n",
      "700:\ttotal: 32.8s\tremaining: 14s\n",
      "800:\ttotal: 37.4s\tremaining: 9.3s\n",
      "900:\ttotal: 42s\tremaining: 4.62s\n",
      "999:\ttotal: 46.5s\tremaining: 0us\n",
      "  处理折 4/5\n",
      "0:\ttotal: 55.3ms\tremaining: 55.2s\n",
      "100:\ttotal: 4.84s\tremaining: 43.1s\n",
      "200:\ttotal: 9.5s\tremaining: 37.8s\n",
      "300:\ttotal: 14.1s\tremaining: 32.6s\n",
      "400:\ttotal: 18.6s\tremaining: 27.7s\n",
      "500:\ttotal: 23.3s\tremaining: 23.2s\n",
      "600:\ttotal: 28s\tremaining: 18.6s\n",
      "700:\ttotal: 32.6s\tremaining: 13.9s\n",
      "800:\ttotal: 37.1s\tremaining: 9.22s\n",
      "900:\ttotal: 41.6s\tremaining: 4.58s\n",
      "999:\ttotal: 46.2s\tremaining: 0us\n",
      "  处理折 5/5\n",
      "0:\ttotal: 58.8ms\tremaining: 58.7s\n",
      "100:\ttotal: 4.89s\tremaining: 43.5s\n",
      "200:\ttotal: 9.51s\tremaining: 37.8s\n",
      "300:\ttotal: 14.3s\tremaining: 33.2s\n",
      "400:\ttotal: 19.1s\tremaining: 28.6s\n",
      "500:\ttotal: 24s\tremaining: 23.9s\n",
      "600:\ttotal: 28.9s\tremaining: 19.2s\n",
      "700:\ttotal: 34.1s\tremaining: 14.6s\n",
      "800:\ttotal: 39.1s\tremaining: 9.72s\n",
      "900:\ttotal: 44.1s\tremaining: 4.84s\n",
      "999:\ttotal: 48.7s\tremaining: 0us\n",
      "处理第 4/4 个基础模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处理折 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   46.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处理折 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   46.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处理折 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   45.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处理折 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   46.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处理折 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   45.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练元模型...\n",
      "Stacking完成\n",
      "Stacking预测完成\n",
      "\n",
      "组合所有预测方法...\n",
      "最终预测组合完成\n"
     ]
    }
   ],
   "source": [
    "# 加权平均的权重 (根据模型在验证集上的表现)\n",
    "weights = val_aucs.copy()\n",
    "\n",
    "# 计算简单平均预测结果\n",
    "try:\n",
    "    simple_avg_pred = simple_averaging(models, test)\n",
    "    print('简单平均预测完成')\n",
    "except Exception as e:\n",
    "    print(f\"简单平均预测失败: {str(e)}\")\n",
    "    # 如果简单平均失败，使用表现最好的模型进行预测\n",
    "    best_model_idx = val_aucs.index(max(val_aucs))\n",
    "    simple_avg_pred = models[best_model_idx].predict_proba(test)[:, 1]\n",
    "    print(f'使用最佳模型 ({[\"LightGBM\", \"XGBoost\", \"CatBoost\", \"RandomForest\"][best_model_idx]}) 作为备选预测')\n",
    "\n",
    "# 使用加权平均进行预测\n",
    "try:\n",
    "    weighted_pred = weighted_averaging(models, weights, test)\n",
    "    print('加权平均预测完成')\n",
    "except Exception as e:\n",
    "    print(f\"加权平均预测失败: {str(e)}\")\n",
    "    # 如果加权平均失败，使用简单平均的结果\n",
    "    weighted_pred = simple_avg_pred\n",
    "    print('使用简单平均结果作为备选预测')\n",
    "\n",
    "# 使用Stacking进行预测\n",
    "try:\n",
    "    meta_model = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "    stacking_pred = stacking(models, meta_model, X_train, y_train, test)\n",
    "    print('Stacking预测完成')\n",
    "except Exception as e:\n",
    "    print(f\"Stacking预测失败: {str(e)}\")\n",
    "    # 如果Stacking失败，使用加权平均的结果\n",
    "    stacking_pred = weighted_pred\n",
    "    print('使用加权平均结果作为备选预测')\n",
    "\n",
    "# 最终融合策略 (加权平均多种融合方法)\n",
    "try:\n",
    "    print('\\n组合所有预测方法...')\n",
    "    final_pred = 0.20 * simple_avg_pred + 0.35 * weighted_pred + 0.45 * stacking_pred\n",
    "    print('最终预测组合完成')\n",
    "except Exception as e:\n",
    "    print(f\"最终融合失败: {str(e)}\")\n",
    "    # 如果最终融合失败，使用表现最好的融合方法结果\n",
    "    if max(val_aucs) == val_aucs[0]:  # LightGBM是最好的模型\n",
    "        final_pred = final_lgbm_model.predict_proba(test)[:, 1]\n",
    "        print('使用LightGBM模型结果作为最终预测')\n",
    "    elif max(val_aucs) == val_aucs[1]:  # XGBoost是最好的模型\n",
    "        final_pred = xgb_model.predict_proba(test)[:, 1]\n",
    "        print('使用XGBoost模型结果作为最终预测')\n",
    "    elif max(val_aucs) == val_aucs[2]:  # CatBoost是最好的模型\n",
    "        final_pred = cat_model.predict_proba(test)[:, 1]\n",
    "        print('使用CatBoost模型结果作为最终预测')\n",
    "    else:  # RandomForest是最好的模型\n",
    "        final_pred = rf_model.predict_proba(test)[:, 1]\n",
    "        print('使用RandomForest模型结果作为最终预测')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b32d323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "生成提交文件...\n",
      "================================================================================\n",
      "\n",
      "提交文件已生成!\n",
      "提交文件保存路径: c:\\Users\\16050\\Desktop\\DataMining\\submission_final.csv\n",
      "简单平均权重: 0.20, 加权平均权重: 0.35, Stacking权重: 0.45\n",
      "最终融合策略: 0.20 * 简单平均 + 0.35 * 加权平均 + 0.45 * Stacking\n"
     ]
    }
   ],
   "source": [
    "# ===================== 生成提交文件 ===================== #\n",
    "print('\\n='*80)\n",
    "print('生成提交文件...')\n",
    "print('='*80)\n",
    "submission['isDefault'] = final_pred\n",
    "submission.to_csv('submission_final.csv', index=False)\n",
    "\n",
    "print('\\n提交文件已生成!')\n",
    "print(f\"提交文件保存路径: {os.path.abspath('submission_final.csv')}\")\n",
    "# 打印各种融合方法的权重\n",
    "print(f'简单平均权重: 0.20, 加权平均权重: 0.35, Stacking权重: 0.45')\n",
    "print('最终融合策略: 0.20 * 简单平均 + 0.35 * 加权平均 + 0.45 * Stacking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
